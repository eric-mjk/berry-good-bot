#!/usr/bin/env python3
import rclpy, math, cv2, torch, numpy as np, os, sys
from rclpy.node            import Node
from rclpy.action          import ActionServer
from sensor_msgs.msg       import Image, CameraInfo
from geometry_msgs.msg     import TransformStamped, PoseStamped, Point, Quaternion
from visualization_msgs.msg import Marker
from tf2_ros               import StaticTransformBroadcaster, Buffer, TransformListener, TransformBroadcaster
import tf_transformations   as tft
from cv_bridge             import CvBridge
from ultralytics           import YOLO
from berry_interface.action import DetectStrawberry, GripperControl
from std_msgs.msg import Int8

from ament_index_python.packages import get_package_share_directory

class PerceptionNode(Node):
    def __init__(self):
        # super().__init__('perception_node')
        super().__init__(
            "perception_node",
            # YAML-override ì—ì„œ ì˜¨ ëª¨ë“  í‚¤ë¥¼ ìë™ ì„ ì–¸
            automatically_declare_parameters_from_overrides=True
        )

        # â”€â”€â”€â”€â”€â”€ Logger â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        self.logger = self.get_logger()
        self.logger.info(f"[INIT] argv â†’ {sys.argv}")
 
        # â”€â”€â”€â”€â”€â”€ Parameters â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        self.declare_parameter('camera_frame', 'camera_link')
        self.declare_parameter('eef_frame',     'link5')
        # self.declare_parameter('camera_to_eef', [0.0, 0.08, 0.045,  math.pi/180*30, -math.pi/2, -math.pi/2]) # xyz + rpy
        self.declare_parameter('camera_to_eef', [0.035, 0.09, 0.045,  math.pi/180*0, -math.pi/2, -math.pi/2]) # xyz + rpy
        cam2eef = self.get_parameter('camera_to_eef').value
        self.logger.debug(f"[PARAM] camera_to_eef = {cam2eef}")
        self.publish_static_tf(cam2eef)

        # â”€â”€â”€â”€â”€â”€ Subscribers / utils â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        self.bridge   = CvBridge()
        self.rgb_sub  = self.create_subscription(Image,  '/camera/camera/color/image_raw', self.rgb_cb, 10)
        self.dep_sub  = self.create_subscription(Image,  '/camera/camera/aligned_depth_to_color/image_raw', self.depth_cb, 10)
        self.info_sub = self.create_subscription(CameraInfo, '/camera/camera/color/camera_info', self.info_cb, 10)

        self.rgb_img   = None
        self.depth_img = None
        self.cam_info  = None

        # TF buffer for base_link ë³€í™˜
        self.tfb  = Buffer()
        self.tfl  = TransformListener(self.tfb, self)
        # ì ‘ê·¼ ëª©í‘œë¥¼ TFë¡œë„ ì‹œê°í™”í•˜ê¸° ìœ„í•œ ë™ì  ë¸Œë¡œë“œìºìŠ¤í„°
        self.tf_dyn = TransformBroadcaster(self)

        # RViz marker publisher
        self.marker_pub = self.create_publisher(Marker, 'strawberry_mark',  10)
        self.appr_pub   = self.create_publisher(Marker, 'approach_mark',    10)

        # â”€â”€â”€â”€â”€â”€ YOLOv8 ì´ˆê¸°í™” â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        pkg_share  = get_package_share_directory('berry_perception')
        model_path = os.path.join(pkg_share, 'model', 'model1.pt')
        self.logger.info(f"[YOLO] loading weights: {model_path}")
        self.model = YOLO(model_path)
        self.model.model.to('cuda:0' if torch.cuda.is_available() else 'cpu')
        self.logger.info(f"[YOLO] device â†’ {self.model.device}")

        # â”€â”€â”€â”€â”€â”€ Action Servers â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        self._action_server = ActionServer(
            self, DetectStrawberry, 'detect_strawberry', self.execute_cb)
        
        self._grip_server = ActionServer(                     # ğŸ”¸ ì¶”ê°€
            self, GripperControl,  'gripper_command', self.gripper_cb)

        # â”€â”€â”€â”€â”€â”€ Gripper Command í† í”½ (2 Hz) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        self.grip_pub   = self.create_publisher(Int8, '/gripper_cmd', 10)
        self._grip_val  = 1                              # ê¸°ë³¸ ì—´ë¦¼
        self.create_timer(0.5, self._tick_grip)         # 2 Hz

    # ----------------- Static TF ----------------------------------
    def publish_static_tf(self, xyzrpy):
        br = StaticTransformBroadcaster(self)
        t  = TransformStamped()
        t.header.stamp    = self.get_clock().now().to_msg()
        t.header.frame_id = self.get_parameter('eef_frame').value
        t.child_frame_id  = self.get_parameter('camera_frame').value
        t.transform.translation.x, t.transform.translation.y, t.transform.translation.z = xyzrpy[:3]
        # q = tft.quaternion_from_euler(*xyzrpy[3:])
        # t.transform.rotation = Quaternion(x=q[0], y=q[1], z=q[2], w=q[3])

        # â”€â”€ (1) ì›ë˜ RPY â†’ í–‰ë ¬ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        base_rot = tft.euler_matrix(*xyzrpy[3:])          # 4Ã—4

        # â”€â”€ (2) ë³´ì •: ì´ˆë¡(Y)ì¶• ê¸°ì¤€ +30Â° ì•ìª½ìœ¼ë¡œ ê¸°ìš¸ì´ê¸° â”€â”€
        tilt_rad = math.radians(35.0)                     # í•„ìš” ì‹œ âˆ’ê°’ìœ¼ë¡œ ë°”ê¿”ë³´ì„¸ìš”
        corr_mat = tft.rotation_matrix(tilt_rad, (0, 1, 0))

        # â”€â”€ (3) ë‘ í–‰ë ¬ ê³± â†’ ìµœì¢… ì¿¼í„°ë‹ˆì–¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        final_q  = tft.quaternion_from_matrix(
                      tft.concatenate_matrices(base_rot, corr_mat))
        t.transform.rotation = Quaternion(
           x=final_q[0], y=final_q[1], z=final_q[2], w=final_q[3])
        br.sendTransform(t)

    # ----------------- Subs ---------------------------------------
    # def rgb_cb(self, msg):   self.rgb_img   = msg
    # def depth_cb(self, msg): self.depth_img = msg
    # def info_cb(self, msg):  self.cam_info  = msg
    def rgb_cb(self, msg):
        self.rgb_img = msg
        if not hasattr(self, "_dbg_rgb_once"):
            self.logger.debug("[CB] first RGB frame received")
            self._dbg_rgb_once = True

    def depth_cb(self, msg):
        self.depth_img = msg
        if not hasattr(self, "_dbg_depth_once"):
            self.logger.debug("[CB] first Depth frame received")
            self._dbg_depth_once = True

    def info_cb(self, msg):
        self.cam_info = msg
        if not hasattr(self, "_dbg_info_once"):
            self.logger.debug("[CB] first CameraInfo received")
            self._dbg_info_once = True

    # ----------------- Main Action --------------------------------
    async def execute_cb(self, goal_handle):
        offset_z = goal_handle.request.offset_z
        self.logger.info(f"[ACTION] new goal: offset_z={offset_z:.3f}")

        # ìµœì‹  frame ì˜¬ ë•Œê¹Œì§€ ëŒ€ê¸°
        while self.rgb_img is None or self.depth_img is None or self.cam_info is None:
            self.logger.info(f"[ACTION] no img!!")
            rclpy.spin_once(self, timeout_sec=0.1)

        cv_img = self.bridge.imgmsg_to_cv2(self.rgb_img, 'bgr8')
        results = self.model.predict(source=cv_img, conf=0.4, save=False, verbose=False)
        if not results or not results[0].boxes:
            self.get_logger().warn('No strawberry detected')
            goal_handle.abort()
            return DetectStrawberry.Result()

        # ê°€ì¥ ë†’ì€ confidence ì„ íƒ
        boxes = results[0].boxes
        best  = boxes[boxes.conf.argmax()]
        self.logger.info(f"[YOLO] {len(boxes)} boxes, best conf={float(best.conf):.3f}")

        x1, y1, x2, y2 = map(int, best.xyxy[0])
        cx, cy = int((x1+x2)/2), int((y1+y2)/2)

        # zê°’(dept) í™•ë³´
        # depth = self.bridge.imgmsg_to_cv2(self.depth_img, 'passthrough')[cy, cx] / 1000.0  # mmâ†’m
        # if depth == 0.0:
        #     goal_handle.abort()
        #     return DetectStrawberry.Result()

        # â”€â”€â”€ ê¹Šì´ ì¶”ì • (ë°•ìŠ¤ ì „ì²´ â†’ ì´ìƒì¹˜ ì œê±° í›„ robust median) â”€â”€â”€â”€
        depth_np = self.bridge.imgmsg_to_cv2(
            self.depth_img, 'passthrough').astype(np.float32) / 1000.0
        win = depth_np[y1:y2, x1:x2].reshape(-1)
        vals = win[(win > 0) & np.isfinite(win)]
        if vals.size == 0:
            self.logger.warn("No valid depth â†’ abort")
            goal_handle.abort()
            return DetectStrawberry.Result()
        med  = np.median(vals)
        mad  = np.median(np.abs(vals - med))
        thresh = 3 * 1.4826 * mad if mad > 0 else np.inf
        inliers = vals[np.abs(vals - med) < thresh]
        # depth = float(np.median(inliers))            # robust depth  :contentReference[oaicite:0]{index=0}
        # â”€â”€â”€ ê¹Šì´ ì¶”ì • ë°©ì‹ ë³€ê²½: í•˜ìœ„ 25 % ê°’ë“¤ì˜ í‰ê·  â”€â”€â”€
        sorted_vals = np.sort(inliers)
        q25_len = max(1, int(len(sorted_vals) * 0.25))
        depth = float(np.mean(sorted_vals[:q25_len]))
        self.logger.info(f"[DEPTH] {len(inliers)}/{len(vals)} inliers, depth={depth:.3f} m")


        self.logger.info(f"[DEPTH] depth({cx},{cy}) = {depth:.3f} m")

        # # í”½ì…€â†’3D (pin-hole)
        # fx = self.cam_info.k[0];  fy = self.cam_info.k[4]
        # cx0 = self.cam_info.k[2]; cy0 = self.cam_info.k[5]
        # X = (cx - cx0) * depth / fx
        # Y = (cy - cy0) * depth / fy
        # Z = depth
        # self.logger.info(f"[PINHOLE] cam-coords X={X:.3f}, Y={Y:.3f}, Z={Z:.3f}")
        # â”€â”€â”€ â‘  Optical-Frame ì¢Œí‘œ (REP-103: xâ†’right, yâ†’down, zâ†’forward)
        fx = self.cam_info.k[0];  fy = self.cam_info.k[4]
        cx0 = self.cam_info.k[2]; cy0 = self.cam_info.k[5]
        x_opt = (cx - cx0) * depth / fx
        y_opt = (cy - cy0) * depth / fy
        z_opt = depth

        # â”€â”€â”€ â‘¡ Optical â†’ Body( camera_link ) ë³€í™˜
        #    Body-Frame : xâ†’forward, yâ†’left, zâ†’up
        X =  z_opt          # forward
        Y = -x_opt          # left
        Z = -y_opt          # up
        self.logger.info(
            f"[PINHOLE] optical (x={x_opt:.3f}, y={y_opt:.3f}, z={z_opt:.3f}) â†’ "
            f"body (X={X:.3f}, Y={Y:.3f}, Z={Z:.3f})")

        st_pose_cam = PoseStamped()
        st_pose_cam.header.stamp = self.rgb_img.header.stamp
        st_pose_cam.header.frame_id = self.get_parameter('camera_frame').value
        self.logger.info(f"[FRAME] frame_id = {st_pose_cam.header.frame_id}")
        st_pose_cam.pose.position = Point(x=X, y=Y, z=Z)
        st_pose_cam.pose.orientation.w = 1.0  # no orientation

        # feedback
        goal_handle.publish_feedback(
            DetectStrawberry.Feedback(strawberry_pose_cam=st_pose_cam))

        p_cam  = np.array([X, Y, Z, 1.0])
        try:
            tf_cam2base = self.tfb.lookup_transform(
                'base_link', st_pose_cam.header.frame_id,
                rclpy.time.Time())                      # ìµœì‹  TF
            mat_cam2base = tft.concatenate_matrices(
                tft.translation_matrix((tf_cam2base.transform.translation.x,
                                        tf_cam2base.transform.translation.y,
                                        tf_cam2base.transform.translation.z)),
                tft.quaternion_matrix(
                    (tf_cam2base.transform.rotation.x,
                     tf_cam2base.transform.rotation.y,
                     tf_cam2base.transform.rotation.z,
                     tf_cam2base.transform.rotation.w)))
        except Exception as e:
            self.get_logger().error(f"TF error: {e}")
            goal_handle.abort()
            return DetectStrawberry.Result()

        st_base = (mat_cam2base @ p_cam)[:3]            # ë”¸ê¸° ìœ„ì¹˜(base)

        # # â‘¡ link4 zì¶•ìœ¼ë¡œ 0.04 m ì´ë™
        # tf_link4 = self.tfb.lookup_transform('base_link', 'link4', rclpy.time.Time())
        # R_link4  = tft.quaternion_matrix((tf_link4.transform.rotation.x,
        #                                   tf_link4.transform.rotation.y,
        #                                   tf_link4.transform.rotation.z,
        #                                   tf_link4.transform.rotation.w))
        # z_axis   = R_link4[:3, 2]
        # appr_pos = st_base + 0.04 * z_axis

        # # â‘¢ link5 ì›ì  â†’ ë”¸ê¸° ë²¡í„° ë°©í–¥ìœ¼ë¡œ offset_z ë§Œí¼ ë‹¹ê²¨ì˜¤ê¸°
        # tf_link5  = self.tfb.lookup_transform('base_link', 'link5', rclpy.time.Time())
        # link5_org = np.array([tf_link5.transform.translation.x,
        #                       tf_link5.transform.translation.y,
        #                       tf_link5.transform.translation.z])
        # vec       = st_base - link5_org
        # vec_norm  = vec / np.linalg.norm(vec)
        # appr_pos  = appr_pos - offset_z * vec_norm

        # â‘¡ ì ‘ê·¼ì  ê³„ì‚° (í•„ìˆ˜: link4ì˜ XY í‰ë©´ìœ¼ë¡œ ì‚¬ì˜í•œ ë²¡í„° ì‚¬ìš©)
        #    - vec = (ë”¸ê¸° - link5 ì›ì )
        #    - vec ì„ link4ì˜ XY í‰ë©´(ë²•ì„  = link4 zì¶•)ìœ¼ë¡œ ì‚¬ì˜ â†’ v_proj
        #    - ìµœì¢… ì ‘ê·¼ì  = st_base + 0.04 * z4  -  offset_z * normalize(v_proj)
        #
        #    ì£¼ì˜: ì‚¬ì˜ ë²¡í„° í¬ê¸°ê°€ ë„ˆë¬´ ì‘ìœ¼ë©´(link4 zì¶•ê³¼ ê±°ì˜ í‰í–‰) link4 xì¶•ì„ ëŒ€ì²´ ë°©í–¥ìœ¼ë¡œ ì‚¬ìš©
        tf_link4 = self.tfb.lookup_transform('base_link', 'link4', rclpy.time.Time())
        R_link4  = tft.quaternion_matrix((
            tf_link4.transform.rotation.x,
            tf_link4.transform.rotation.y,
            tf_link4.transform.rotation.z,
            tf_link4.transform.rotation.w
        ))
        z4 = R_link4[:3, 2]    # link4 z-axis (plane normal)

        tf_link5  = self.tfb.lookup_transform('base_link', 'link5', rclpy.time.Time())
        link5_org = np.array([
            tf_link5.transform.translation.x,
            tf_link5.transform.translation.y,
            tf_link5.transform.translation.z
        ])
        vec      = st_base - link5_org
        # (orientation ê³„ì‚°ì—ì„œ ì‚¬ìš©í•˜ë¯€ë¡œ ê¸°ì¡´ ì •ê·œí™” ë²¡í„°ë„ ìœ ì§€)
        vec_norm = vec / (np.linalg.norm(vec) + 1e-12)

        # link4 XY í‰ë©´ìœ¼ë¡œ ì‚¬ì˜
        v_proj   = vec - np.dot(vec, z4) * z4
        n_proj   = np.linalg.norm(v_proj)
        if n_proj < 1e-6:
            # ì‚¬ì˜ì´ ê±°ì˜ 0ì´ë©´ link4 xì¶•ì„ ì•ˆì „í•œ ëŒ€ì²´ ë°©í–¥ìœ¼ë¡œ ì‚¬ìš©
            x4   = R_link4[:3, 0]
            v_dir = x4 / (np.linalg.norm(x4) + 1e-12)
        else:
            v_dir = v_proj / n_proj

        # ìµœì¢… ì ‘ê·¼ì : ì‚¬ì˜ëœ í‰ë©´ ë°©í–¥ìœ¼ë¡œ offset, ê·¸ë¦¬ê³  link4 zì¶•ìœ¼ë¡œ 0.04 ìƒìŠ¹
        appr_pos = st_base + 0.02 * z4 - offset_z * v_dir
        # # â‘£ EEF orientation: x-axisë¥¼ vec ë°©í–¥ìœ¼ë¡œ ì •ë ¬
        # x_axis = vec_norm
        # z_ref  = np.array([0.0, 0.0, 1.0])
        # y_axis = np.cross(z_ref, x_axis)
        # if np.linalg.norm(y_axis) < 1e-4:
        #     y_axis = np.array([0.0, 1.0, 0.0])
        # y_axis /= np.linalg.norm(y_axis)
        # z_axis_eef = np.cross(x_axis, y_axis)
        # # R_eef = np.eye(4)
        # # R_eef[:3, 0] = x_axis
        # # R_eef[:3, 1] = y_axis
        # # R_eef[:3, 2] = z_axis_eef
        # # q_eef = tft.quaternion_from_matrix(R_eef)

        # # --- ì¶• ì¬ë§¤í•‘ ---
        # # ìš”êµ¬ì‚¬í•­:
        # #   í˜„ì¬ xì¶• â†’ zì¶•,  yì¶• â†’ xì¶•,  zì¶• â†’ yì¶•
        # # ì¦‰, new_x = old_y, new_y = old_z, new_z = old_x
        # R_eef = np.eye(4)
        # # col0(x) := old y
        # R_eef[:3, 0] = y_axis
        # # col1(y) := old z
        # R_eef[:3, 1] = z_axis_eef
        # # col2(z) := old x
        # R_eef[:3, 2] = x_axis
        # q_eef = tft.quaternion_from_matrix(R_eef)

        # â‘£ EEF orientation (yì¶• ê³ ì •):
        #    - link5ì˜ yì¶•ì€ ìœ ì§€
        #    - (ë”¸ê¸° - link5) ë²¡í„°ë¥¼ link5ì˜ XZ í‰ë©´ì— ì‚¬ì˜
        #    - ì‚¬ì˜ëœ ë²¡í„° ë°©í–¥ìœ¼ë¡œ zì¶•ì„ ì •ë ¬
        #    - xì¶•ì€ y Ã— zë¡œ ì§êµí™”(ìš°ìˆ˜ì¢Œë²• ìœ ì§€)
        #
        #    ì°¸ê³ : link5ì˜ í˜„ì¬ ì¶•ì€ R_link5ì˜ ì»¬ëŸ¼ ë²¡í„°
        R_link5 = tft.quaternion_matrix((
            tf_link5.transform.rotation.x,
            tf_link5.transform.rotation.y,
            tf_link5.transform.rotation.z,
            tf_link5.transform.rotation.w
        ))
        x5 = R_link5[:3, 0]
        y5 = R_link5[:3, 1]   # ğŸ”’ ê³ ì •í•´ì•¼ í•˜ëŠ” ì¶•
        z5 = R_link5[:3, 2]
        # (1) vecì„ y5ì— ìˆ˜ì§í•œ í‰ë©´(= link5 XZ í‰ë©´)ì— ì‚¬ì˜
        v_proj = vec_norm - np.dot(vec_norm, y5) * y5
        n_v = np.linalg.norm(v_proj)
        if n_v < 1e-6:
            # ì‚¬ì˜ì´ ê±°ì˜ 0ì´ë©´ í˜„ì¬ zì¶• ìœ ì§€(íŠ¹ì´ìƒí™©)
            z_axis_eef = z5 / np.linalg.norm(z5)
        else:
            z_axis_eef = v_proj / n_v
        # (2) yì¶•ì€ ìœ ì§€, xì¶•ì€ y Ã— z ë¡œ ê²°ì •(ì •ê·œí™”)
        y_axis = y5 / np.linalg.norm(y5)
        x_axis = np.cross(y_axis, z_axis_eef)
        nx = np.linalg.norm(x_axis)
        if nx < 1e-6:
            # í˜¹ì‹œë¼ë„ ìˆ˜ì¹˜ ë¬¸ì œë©´ ê¸°ì¡´ x5 ì‚¬ìš©
            x_axis = x5 / np.linalg.norm(x5)
            # z ì¬ê³„ì‚°ìœ¼ë¡œ ì§êµí™” ì‹œë„
            z_axis_eef = np.cross(x_axis, y_axis)
            z_axis_eef /= (np.linalg.norm(z_axis_eef) + 1e-12)
        else:
            x_axis /= nx
            # zë¥¼ ë‹¤ì‹œ í•œë²ˆ ì§êµí™”(ìˆ˜ì¹˜ ì•ˆì •)
            z_axis_eef = np.cross(x_axis, y_axis)
            z_axis_eef /= (np.linalg.norm(z_axis_eef) + 1e-12)

        # --- (í•„ìš”í•œ í”„ë ˆì„ ë§¤í•‘ì´ ìˆì„ ê²½ìš°) ì¶• ì¬ë§¤í•‘ ìœ ì§€ ---
        # ê¸°ì¡´ ìš”êµ¬ì‚¬í•­:
        #   í˜„ì¬ xì¶• â†’ zì¶•,  yì¶• â†’ xì¶•,  zì¶• â†’ yì¶•
        # ì¦‰, ìµœì¢… íšŒì „í–‰ë ¬ì˜ ì»¬ëŸ¼ ìˆœì„œë¥¼ [y, z, x]ë¡œ ë°°ì¹˜
        R_eef = np.eye(4)
        # R_eef[:3, 0] = y_axis        # new x  <- old y
        # R_eef[:3, 1] = z_axis_eef    # new y  <- old z
        # R_eef[:3, 2] = x_axis        # new z  <- old x
        R_eef[:3, 0] = x_axis        # new x  <- old y
        R_eef[:3, 1] = y_axis   # new y  <- old z
        R_eef[:3, 2] = z_axis_eef        # new z  <- old x
        q_eef = tft.quaternion_from_matrix(R_eef)

        # â”€â”€â”€ ìµœì¢… approach pose ë¡œê·¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        self.logger.info(f"[TF] approach(base_link) = {appr_pos}")

        appro_pose_base = PoseStamped()
        appro_pose_base.header.frame_id = 'base_link'
        appro_pose_base.header.stamp = self.get_clock().now().to_msg()

        appro_pose_base.pose.position = Point(
            x=float(appr_pos[0]),
            y=float(appr_pos[1]),
            z=float(appr_pos[2]),
         )
        appro_pose_base.pose.orientation = Quaternion(
            x=float(q_eef[0]), y=float(q_eef[1]),
            z=float(q_eef[2]), w=float(q_eef[3]))

        # RViz ë§ˆì»¤ ë‘ ê°œ ---------------------------------------------------
        self.publish_marker(st_pose_cam, id=0, color=(1.0, 0.0, 0.0))  # red
        self.publish_marker(appro_pose_base, id=1, color=(0.0, 1.0, 0.0))  # green

        # â”€â”€ ì ‘ê·¼ ëª©í‘œë¥¼ TFë¡œë„ publish (base_link -> approach_target) â”€â”€
        t = TransformStamped()
        t.header.stamp = self.get_clock().now().to_msg()
        t.header.frame_id = 'base_link'
        t.child_frame_id  = 'approach_target'   # RVizì—ì„œ ì´ í”„ë ˆì„ ì„ íƒí•´ í™•ì¸
        t.transform.translation.x = appro_pose_base.pose.position.x
        t.transform.translation.y = appro_pose_base.pose.position.y
        t.transform.translation.z = appro_pose_base.pose.position.z
        t.transform.rotation      = appro_pose_base.pose.orientation
        self.tf_dyn.sendTransform(t)

        goal_handle.succeed()
        return DetectStrawberry.Result(approach_pose_base=appro_pose_base)

    # ----------------- RViz marker util ----------------------------
    def publish_marker(self, pose, id, color):
        m = Marker()
        m.header = pose.header
        m.ns = 'berry'
        m.id = id
        m.type = Marker.SPHERE
        m.action = Marker.ADD
        m.pose = pose.pose
        m.scale.x = m.scale.y = m.scale.z = 0.03
        m.color.r, m.color.g, m.color.b = color
        m.color.a = 0.8
        pub = self.marker_pub if id == 0 else self.appr_pub
        pub.publish(m)

    # ----------------- Gripper Action -----------------------------
    async def gripper_cb(self, goal_handle):
        self._grip_val = 1 if goal_handle.request.open else 0
        self.logger.info(f"[GRIPPER] â†’ {'OPEN' if self._grip_val else 'CLOSE'}")
        goal_handle.succeed()
        return GripperControl.Result(done=True)

    def _tick_grip(self):
        msg = Int8(data=self._grip_val)
        self.grip_pub.publish(msg)

def main():
    rclpy.init()
    rclpy.spin(PerceptionNode())
    rclpy.shutdown()
